{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "nbpresent": {
     "id": "25c7093b-556b-4c08-b249-b30edea100f7"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nikitavemuri/anaconda/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "/Users/nikitavemuri/anaconda/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "nbpresent": {
     "id": "631f9391-dba5-480c-a928-2950874f2998"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/train-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST/train-labels-idx1-ubyte.gz\n",
      "Extracting data/MNIST/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "MNIST = input_data.read_data_sets('data/MNIST/', one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "82e859b9-c8ba-4e31-add1-d13a9a38dce0"
    }
   },
   "source": [
    "<img src=\"cnn.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "d792b8a5-fb49-484c-8957-48f4e01d37b2"
    }
   },
   "source": [
    "### CNN Configurations\n",
    "Fill out the configuration of the CNN based on the image above. \n",
    "* Assume that each convolutional layer is zero padded appropriately so that the convolutional layer does not decrease the width or height of the image. \n",
    "* After each convolutional layer and ReLu layer, there will be a max pool layer which decreases the image size by 2.\n",
    "* Note that the number of filters in the convolution corresponds to the number of channels of the output volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "0b2ff275-5908-4d83-b982-af49d1915787"
    }
   },
   "outputs": [],
   "source": [
    "# Input\n",
    "img_size = 28                               # MNIST images are 28x28# Size of MNIST image in 1D array\n",
    "img_size_flat = img_size * img_size         # Size of MNIST image in 1D array\n",
    "num_channels = 1                            # 1 channel because images are grayscale\n",
    "num_classes = 10                            # Number of classes, one class for each of 10 digits.\n",
    "\n",
    "# Convolutional Layer 1.\n",
    "filter_size1 = ...\n",
    "num_filters1 = ...\n",
    "\n",
    "# Convolutional Layer 2.\n",
    "filter_size2 = ...\n",
    "num_filters2 = ...\n",
    "\n",
    "# Fully-connected layer.\n",
    "fc_size = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "af0ce285-da21-44f3-aef9-b82069159e5f"
    }
   },
   "source": [
    "Fill in the following helper functions to create new weight and bias tensors of a given shape. \n",
    "* Let the weights be initialized to values from the truncated normal distribution with a standard deviation of 0.1.\n",
    "* Let the bias be initialized to a tensor of zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "5b8f020c-f121-4c74-a87d-b5a9b7302f5c"
    }
   },
   "outputs": [],
   "source": [
    "def new_weights(shape):\n",
    "    return tf.Variable(tf.truncated_normal(...))\n",
    "\n",
    "def new_biases(shape):\n",
    "    return tf.Variable(tf.zeros(...))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "93044d7b-ce2b-4adf-8ada-a104198c5979"
    }
   },
   "source": [
    "### Convolutional Layer\n",
    "Fill in the following function to create a new convolutional layer using tf.layers.conv2d() by first creating a convolutional layer, then using pooling if required, then applying ReLU.\n",
    "* Make sure zero padding is appropriately used so the width and height of the output of the convolutional layer match that of the input layer\n",
    "* Use a stride of 1 in all directions\n",
    "* If use_pooling = True, use 2x2 max pooling with tf.layers.max_pooling2d() to half the width and height of the input\n",
    "    * Hint: Use the formula $W_2 = \\frac{W_1-F}{S} + 1$ where $W_2 = \\frac{W_1}{2}$ to calculate the appropriate stride\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "1a46bf01-a353-49d3-8684-e982b38b3636"
    }
   },
   "outputs": [],
   "source": [
    "def new_conv_layer(input_layer, filter_size, num_filters, use_pooling=True):  \n",
    "    output = tf.layers.conv2d(inputs = ..., kernel_size = ..., \n",
    "                              filters = ..., padding = ..., strides = ...)\n",
    "    \n",
    "    if use_pooling:\n",
    "        output = tf.layers.max_pooling2d(inputs = ..., pool_size = ..., strides = ...)\n",
    "        \n",
    "    output = ...\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat the above function, but use tf.nn.conv2d() this time to create the convolutional layer.\n",
    "* Remember: Unlike while using tf.layers.conv2d(), tf.nn.conv2d() requires the actual filter tensor as an input instead of just the size of the filter\n",
    "    * To do this, use the new_weights() function defined above.\n",
    "    * Also remember to add a bias for each filter after creating a convolutional layer with tf.nn.conv2d(). tf.layers.conv2d() adds a bias tensor by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def new_conv_layer_nn(input_layer, filter_size, num_filters, use_pooling=True):  \n",
    "    input_shape = input_layer.get_shape().as_list()\n",
    "    w_shape = [...]\n",
    "    weights = new_weights(w_shape)\n",
    "    biases = new_biases(...)\n",
    "    \n",
    "    output = tf.nn.conv2d(input = ..., filter = ..., padding = ..., strides = ...)\n",
    "    output += ...\n",
    "    \n",
    "    if use_pooling:\n",
    "        output = tf.layers.max_pooling2d(inputs = ..., pool_size=2, strides = 2)\n",
    "    output = tf.nn.relu(output)\n",
    "          \n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test dimensions to make sure that both new_conv_layer functions work as expected.\n",
    "<br>\n",
    "* Create a placeholder value for each image with shape [batch size, image flattened size]\n",
    "* Reshape that placeholder into the shape [batch size, image height, image width, number of channels]. This is the format of the input that is required for both tf.layers.conv2d() and tf.nn.conv2d()\n",
    "    * Hint: Using -1 as one of the lengths of a dimension causes tensorflow to infer the length of that dimension depending on the size of the input and the lengths of the other dimensions provided. This will be useful because you don't yet know what the batch size is.\n",
    "* Create a placeholder value for each label with shape [batch size, number of classes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "e55bf768-3a35-4cf3-8122-b72ab918f98d"
    }
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=[...], name = 'X')\n",
    "x_img = tf.reshape(X, [...])\n",
    "y = tf.placeholder(tf.float32, shape = [...], name = 'y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Using the new_conv_layer() function created above, create layer 1 and layer 2 of the CNN based on the configuration of the CNN and the image above. \n",
    "* Check the shape of the output of layer 1 and layer 2 to make sure they are accurate. \n",
    "* Change new_conv_layer() function to new_conv_layer_nn() and make sure the output shapes are still accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "21d4d45d-b8fd-43d1-8ff9-36a5ab263010"
    }
   },
   "outputs": [],
   "source": [
    "layer_conv1 = new_conv_layer(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "nbpresent": {
     "id": "d2243645-bfb5-417d-8134-b2e07ad47c63"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Relu:0' shape=(?, 14, 14, 16) dtype=float32>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_conv1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "2eb8c35f-664b-40c3-9626-08937ee9501c"
    }
   },
   "outputs": [],
   "source": [
    "layer_conv2 = new_conv_layer(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "nbpresent": {
     "id": "6ef75c1a-bef0-4c3e-bea0-1042d63b00b2"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Relu_1:0' shape=(?, 7, 7, 36) dtype=float32>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_conv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully Connected Layers\n",
    "Create a function to flatten a given layer of shape [batch size, ...] into [batch size, number of features]\n",
    "* Hint: Tensor_Shape.num_elements() returns the total number of elements in a tensor of given shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "93b8cd1e-53fa-4ec8-8b85-f09752301a47"
    }
   },
   "outputs": [],
   "source": [
    "def flatten_layer(layer):\n",
    "    num_features = ...\n",
    "    return tf.reshape(layer, [-1, ...])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function for a fully connected layer with the input layer having shape [batch size, number of input features] and the output layer having shape [batch size, num_outputs]\n",
    "* Define the weight and bias tensors and apply them on the input layer\n",
    "* Use a ReLU activation if appropriate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "c8c4b28c-99f8-4b5f-a429-f5ed72923c74"
    }
   },
   "outputs": [],
   "source": [
    "def new_fc_layer(layer, num_outputs, use_relu=True):\n",
    "    num_inputs = layer.get_shape().as_list()[1]\n",
    "    w = new_weights(shape = [...])\n",
    "    b = new_biases(shape = ...)\n",
    "    \n",
    "    layer = ...\n",
    "    \n",
    "    if use_relu:\n",
    "        layer = ...\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flatten the last convolutional layer and check that its shape is equal to the product of the last three dimensions of layer_conv2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "nbpresent": {
     "id": "f2dbf140-5d5c-44ed-abad-db5050350882"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Reshape_1:0' shape=(?, 1764) dtype=float32>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_flat = flatten_layer(...)\n",
    "layer_flat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a fully connected layer of the appropriate size based on the CNN configurations and check the size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "86417dfd-e697-41f2-a178-32a046a339b1"
    }
   },
   "outputs": [],
   "source": [
    "layer_fc1 = new_fc_layer(layer = ..., num_outputs = ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "nbpresent": {
     "id": "9e0fc369-0225-4a0f-9b8e-5d6aeb998343"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Relu_2:0' shape=(?, 128) dtype=float32>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_fc1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add a dropout layer after the first fully connected layer by creating a placeholder keep_prob, which is a parameter to tf.nn.dropout(). This allows dropout to be on during training and off during testing. When training the model, set keep_prob to a fraction (such as 0.5) and when testing, set keep_prob to 1.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'dropout/mul:0' shape=(?, 128) dtype=float32>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keep_prob = tf.placeholder(...)\n",
    "layer_fc1 = tf.nn.dropout(...)\n",
    "layer_fc1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the final fully connected layer and check the size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "ae1441dc-8e90-422d-bd55-97c0f6b6c9ed"
    }
   },
   "outputs": [],
   "source": [
    "layer_fc2 = new_fc_layer(layer = ..., num_outputs = ..., use_relu=...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "nbpresent": {
     "id": "abce0e8d-b796-478f-8c22-d6df83ecdd5e"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'add_3:0' shape=(?, 10) dtype=float32>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_fc2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply softmax to the final fully connected layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "92c7af29-58c5-4c9f-a6be-c16360fd4ffc"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = tf.nn.softmax(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The class of the predicted and true y is obtained with argmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-21-9c347b2d38b6>:1: calling argmax (from tensorflow.python.ops.math_ops) with dimension is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the `axis` argument instead\n"
     ]
    }
   ],
   "source": [
    "y_pred_cls = tf.argmax(y_pred, dimension = 1)\n",
    "y_cls = tf.argmax(y, dimension = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization and Accuracy\n",
    "Set entropy to be cross entropy and the loss to be the mean of the entropy. Use the Adam Optimizer with a learning rate of 0.01 to minimize the loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "b99a3071-61ab-423a-a328-18d813bcb5fc"
    }
   },
   "outputs": [],
   "source": [
    "entropy = tf.nn.softmax_cross_entropy_with_logits(logits = ..., labels = ...)\n",
    "loss = tf.reduce_mean(...)\n",
    "optimizer = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy is computed by:\n",
    "* Checking if y_pred_cls = y_cls and casting this value as a float\n",
    "* Finding the mean of y_pred_cls = y_cls for each example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "5efaf5a4-f48b-4b06-b920-6a9bde812134"
    }
   },
   "outputs": [],
   "source": [
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(y_pred_cls, y_cls), tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "nbpresent": {
     "id": "36d65090-1a76-4f18-b72c-794b04434df7"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-9a831d719701>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInteractiveSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill in the optimize function which will run a certain number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_epochs = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def optimize(epochs):\n",
    "    global total_epochs\n",
    "    batch_size = 64\n",
    "    num_batches = int(...)\n",
    "    for epoch in range(total_epochs, total_epochs+epochs):\n",
    "        total_loss = 0\n",
    "        for batch in range(num_batches):\n",
    "            x, y_ = ...\n",
    "            _, l = sess.run([...], feed_dict = {...})\n",
    "            total_loss += l\n",
    "        print(\"Epoch {0}: {1}\".format(epoch, total_loss))\n",
    "    total_epochs += epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimize for a few iterations and print the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "nbpresent": {
     "id": "7a90cd73-e8cd-4eba-8cff-a8a7f9f5f2d4"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 188.83070358075202\n",
      "Epoch 1: 110.50036576404818\n",
      "Epoch 2: 99.88425283459947\n"
     ]
    }
   ],
   "source": [
    "optimize(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "nbpresent": {
     "id": "317cda7e-01c9-4d33-89f2-ed7e4e82db12"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing accuracy ...\n",
      "Accuracy 0.9835000038146973\n"
     ]
    }
   ],
   "source": [
    "# Testing\n",
    "print(\"Computing accuracy ...\")\n",
    "X_batch, y_batch = MNIST.test.next_batch(MNIST.test.num_examples)\n",
    "total_accuracy = sess.run(accuracy, feed_dict={X: X_batch, y: y_batch, keep_prob: 1.0})\n",
    "\n",
    "print (\"Accuracy {0}\".format(total_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
