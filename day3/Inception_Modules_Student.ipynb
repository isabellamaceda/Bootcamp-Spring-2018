{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Inception Modules.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "lJll_Qkr3CCP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Inception Modules"
      ]
    },
    {
      "metadata": {
        "id": "zT8r3A2ySYK_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Since you already learned how to build a CNN using low-level TF libraries, we won't bother with that here. Let's use tf.layers to easily create our model. "
      ]
    },
    {
      "metadata": {
        "id": "G2Q1NZYMSoyu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let's first donwload our data. Also make sure you are running this notebook in GPU node."
      ]
    },
    {
      "metadata": {
        "id": "x87i33Oq5C0Z",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "__HOB8Fd5LBd",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.cifar100.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s97Nq0Qr5frp",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "X_train = X_train.astype('float32') / 255\n",
        "X_test = X_test.astype('float32') / 255\n",
        "y_train = y_train.ravel().astype('int64')\n",
        "y_test = y_test.ravel().astype('int64')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0EV4AQvlYeSK",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "conv2d = tf.layers.conv2d\n",
        "max_pooling2d = tf.layers.max_pooling2d\n",
        "average_pooling2d = tf.layers.average_pooling2d\n",
        "relu = tf.nn.relu"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bK8exMD3S0S3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Take a look at what the high-level architecture of our CNN is gonna look like."
      ]
    },
    {
      "metadata": {
        "id": "sWNUBez9lMhS",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def cnn_model_fn(features, labels, mode, params=None):\n",
        "  \n",
        "  # Reshape X to 4-D tensor: [batch_size, width, height, channels]\n",
        "  input_layer = tf.reshape(features[\"x\"], [-1, 32, 32, 3])\n",
        " \n",
        "  # MODULE 1 - Output Tensor Shape: [batch_size, 32, 32, 96]\n",
        "  mod1 = module1(input_layer)\n",
        "  \n",
        "  # do a 2x2 maxpool with 2 strides\n",
        "  # Output Tensor Shape: [batch_size, 16, 16, 96]\n",
        "  pool1 = ...\n",
        "  \n",
        "  # MODULE 2 - Output Tensor Shape: [batch_size, 16, 16, 96]\n",
        "  mod2 = module2(pool1)\n",
        "  \n",
        "  # RESNET\n",
        "  # don't worry about this until the very end\n",
        "\n",
        "  # reduce dimensions - do a conv 1x1 kernel filter with relu\n",
        "  # Output Tensor Shape: [batch_size, 16, 16, 24]\n",
        "  conv = ...\n",
        "\n",
        "  # do a 2x2 average pool with 2 strides\n",
        "  # Output Tensor Shape: [batch_size, 8, 8, 24]\n",
        "  pool2 = ...\n",
        "  \n",
        "  # Output Tensor Shape: [batch_size, 8 * 8 * 24]\n",
        "  pool2_flat = tf.reshape(pool2, [-1, 8 * 8 * 24])\n",
        "\n",
        "  # do a dense layer with 1000 units with relu\n",
        "  # Output Tensor Shape: [batch_size, 1000]\n",
        "  dense = ...\n",
        "  \n",
        "  dropout = tf.layers.dropout(\n",
        "      inputs=dense, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN)\n",
        "\n",
        "  # Output Tensor Shape: [batch_size, 100]\n",
        "  logits = tf.layers.dense(inputs=dropout, units=100)\n",
        "\n",
        "  loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
        "  \n",
        "  \n",
        "  # Don't worry about anything below ------------------------------------------\n",
        "\n",
        "  predictions = {\n",
        "      \"classes\": tf.argmax(input=logits, axis=1),\n",
        "      \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
        "  }\n",
        "  \n",
        "  if mode == tf.estimator.ModeKeys.PREDICT:\n",
        "    return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
        "\n",
        "  if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "    optimizer = tf.train.AdamOptimizer(learning_rate=params['lr'])\n",
        "    train_op = optimizer.minimize(\n",
        "        loss=loss,\n",
        "        global_step=tf.train.get_global_step())\n",
        "    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
        "\n",
        "  if mode == tf.estimator.ModeKeys.EVAL:\n",
        "    eval_metric_ops = {\n",
        "        \"accuracy\": tf.metrics.accuracy(\n",
        "            labels=labels, predictions=predictions[\"classes\"])}\n",
        "    return tf.estimator.EstimatorSpec(\n",
        "        mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7YH_yrZkZ-wH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This is going to be a naive module. We want 3 branches - one for each kernel dimension (1x1, 3x3, 5x5). Then we're going to do a depth-wise concatenation and return the output. For each branch, use a convolution on the input with 32 output filters, stride=1, padding=same, and relu activation. Finally, do a depth-wise concatenation of all 3 branches (essentially stacking them on top of each other)."
      ]
    },
    {
      "metadata": {
        "id": "AuTGdA6VSygL",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def module1(input_layer):\n",
        "  # Input Tensor Shape: [batch_size, 32, 32, 3]\n",
        "  \n",
        "  # 1x1 convolution\n",
        "  # Output Tensor Shape: [batch_size, 32, 32, 32]\n",
        "  branch1 = ...\n",
        "\n",
        "  # 3x3 convolution\n",
        "  # Output Tensor Shape: [batch_size, 32, 32, 32]\n",
        "  branch2 = ...\n",
        "\n",
        "  # 5x5 convolution\n",
        "  # Output Tensor Shape: [batch_size, 32, 32, 32]\n",
        "  branch3 = ...\n",
        "  \n",
        "  # Output Tensor Shape: [batch_size, 32, 32, 96]\n",
        "  module = ...\n",
        "  \n",
        "  return module"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "M3JREmIUrcpk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now we're going to do the better inception module. What this means is that we add a dimensionality reduction before the 3x3 and 5x5 kernels with a 1x1 feature map reduction convolution. Let's also add a 4th branch that does a 3x3 maxpool followed by a 1x1 dimensionality reduction convolution. Then we can concatenate them all.\n"
      ]
    },
    {
      "metadata": {
        "id": "zWt8KAemVVQD",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def module2(input_layer):\n",
        "  # Input Tensor Shape: [batch_size, 16, 16, 96]\n",
        "  \n",
        "  # 1x1 convolution\n",
        "  # Output Tensor Shape: [batch_size, 16, 16, 24]\n",
        "  branch1 = ...\n",
        "  \n",
        "  # 1x1 conv followed by 3x3 conv, same filter #s\n",
        "  # Output Tensor Shape: [batch_size, 16, 16, 24]\n",
        "  branch2 = ...\n",
        "  branch2 = ...\n",
        "  \n",
        "  # 1x1 conv followed by 5x5 conv, same filter #s\n",
        "  # Output Tensor Shape: [batch_size, 16, 16, 24]\n",
        "  branch3 = ...\n",
        "  branch3 = ...\n",
        "  \n",
        "  # 3x3 maxpool followed by 1x1 conv\n",
        "  # Output Tensor Shape: [batch_size, 16, 16, 24]\n",
        "  branch4 = ...\n",
        "  branch4 = ...\n",
        "\n",
        "  # Output Tensor Shape: [batch_size, 16, 16, 96]\n",
        "  module = ...\n",
        "  \n",
        "  return module"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "B26izjxjbDXJ",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Create the Estimator\n",
        "classifier = tf.estimator.Estimator(model_fn=cnn_model_fn, params={'lr':0.001})\n",
        "\n",
        "# Train the model\n",
        "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
        "    x={\"x\": X_train},\n",
        "    y=y_train,\n",
        "    batch_size=250,\n",
        "    num_epochs=None,\n",
        "    shuffle=True)\n",
        "\n",
        "# Evaluate the model\n",
        "eval_input_fn = lambda X, y: tf.estimator.inputs.numpy_input_fn(\n",
        "    x={\"x\": X},\n",
        "    y=y,\n",
        "    num_epochs=1,\n",
        "    shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "x08Fc1BodVta",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "train_accs, val_accs = [], []\n",
        "for i in range(5):\n",
        "  classifier.train(input_fn=train_input_fn, steps=500 if i else 1)\n",
        "  train_accs.append(classifier.evaluate(input_fn=eval_input_fn(X_train, y_train)))\n",
        "  val_accs.append(classifier.evaluate(input_fn=eval_input_fn(X_test, y_test)))\n",
        "  print('train acc:', train_accs[-1])\n",
        "  print('val acc:', val_accs[-1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vS4xhA9hI7TD",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "plt.plot([t['loss'] for t in train_accs], label='train')\n",
        "plt.plot([t['loss'] for t in val_accs], label='val')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}